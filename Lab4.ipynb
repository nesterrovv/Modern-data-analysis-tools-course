{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modern tools of Data Analysis, Lab4, Nesterov.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs6Yt1h1pO-0"
      },
      "source": [
        "В данной лабораторной работе будут показаны основы анализа текстовой информации. В ходе её выполнения мы познакомимся с этапами предварительной подготовки данных, а также применим машинное обучение для задачи классификации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiY7HEwBA5ht"
      },
      "source": [
        "Будем использовать датасет с текстами песен разных жанров: https://www.kaggle.com/mehedihasan9021/movie-script-dataset\n",
        "\n",
        "\n",
        "> Задание выполняется в google colab. Чтобы редактировать ноутбук, не забудьте сохранить его копию на диске. Скачайте файл по ссылке, загрузите в сессионное хранилище и запускайте ячейки с кодом, следуя инструкциям."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GnC1RxfW78B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqSLYPq4XoXH"
      },
      "source": [
        "Читаем набор данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1s8oOBBKaNj"
      },
      "source": [
        "# 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9OwJhjSnzjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316cfad4-818d-4e3a-fab6-61d80e4f03fb"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "NwVymy9wMHSF",
        "outputId": "a114fa13-5104-4156-9424-138b24139cdf"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>SongInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>CASTING CROWNS - WHO AM I LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>GLORY REVEALED - BY HIS WOUNDS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>CAEDMON'S CALL - GOD OF WONDERS LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>MERCYME - I CAN ONLY IMAGINE LYRICS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>AARON SHUST - MY SAVIOR MY GOD LYRICS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       genre  ...                                SongInfo\n",
              "0  Christian  ...        CASTING CROWNS - WHO AM I LYRICS\n",
              "1  Christian  ...   GLORY REVEALED - BY HIS WOUNDS LYRICS\n",
              "2  Christian  ...  CAEDMON'S CALL - GOD OF WONDERS LYRICS\n",
              "3  Christian  ...     MERCYME - I CAN ONLY IMAGINE LYRICS\n",
              "4  Christian  ...   AARON SHUST - MY SAVIOR MY GOD LYRICS\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpByjtHQMASx",
        "outputId": "dc8e0f78-2046-4f0d-8691-f79e3a60713d"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 558 entries, 0 to 557\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   genre     558 non-null    object\n",
            " 1   lyrics    558 non-null    object\n",
            " 2   SongInfo  558 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 13.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxP-iGu-MCi4"
      },
      "source": [
        "columns = data[['genre', 'lyrics']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "bYF8acQSM6zE",
        "outputId": "681b0c2b-9b17-4b97-c079-02a911be3328"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Ha I dont care ha, about your past I just wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Hoverin by my suitcase  Tryin to find a warm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>I dont know why I love you like I do  After a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>C. C. Rider Elvis Presley  Well now see., C. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Cynthia get up and dance to the music!  Get o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>558 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre                                             lyrics\n",
              "0    Christian   Who am I, that the Lord of all the earth Woul...\n",
              "1    Christian   Glory Revealed  By His Wounds He was pierced ...\n",
              "2    Christian   Lord of heaven and earth Lord of all creation...\n",
              "3    Christian   I can only imagine what it will be like When ...\n",
              "4    Christian   I am not skilled to understand What God has w...\n",
              "..         ...                                                ...\n",
              "553        R&B   Ha I dont care ha, about your past I just wan...\n",
              "554        R&B   Hoverin by my suitcase  Tryin to find a warm ...\n",
              "555        R&B   I dont know why I love you like I do  After a...\n",
              "556        R&B   C. C. Rider Elvis Presley  Well now see., C. ...\n",
              "557        R&B   Cynthia get up and dance to the music!  Get o...\n",
              "\n",
              "[558 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM6VU_qPXvId"
      },
      "source": [
        "Посмотрим какие жанры присутствуют в датасете. Для этого выведем уникальные значения столбца:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgU-qG2iM74F",
        "outputId": "2c0cd6c4-b655-4ae7-bc23-df635c0f144b"
      },
      "source": [
        "columns['genre'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Christian', 'Country', 'Hip-Hop', 'Pop', 'Rock', 'R&B'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De2qmchpX2-a"
      },
      "source": [
        "Посчитаем также сколько песен каждого жанра представлено:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQotoiKyOMwl",
        "outputId": "17b8d188-751b-4317-856a-90bcd17c443d"
      },
      "source": [
        "columns['genre'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pop          100\n",
              "Rock          95\n",
              "Christian     94\n",
              "R&B           91\n",
              "Hip-Hop       91\n",
              "Country       87\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSGSPwtzxlyA"
      },
      "source": [
        "Оставляем только 2 жанра, которые планируем отличать друг от друга. Для примера будут использованы Christian и Hip-Hop, позднее в формулировке задания нужно будет сгенерировать собственную пару жанров. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC3pzAFS1ofC"
      },
      "source": [
        "columns = columns[(columns.genre == 'Christian') | (columns.genre == 'Hip-Hop')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aT2_kEVY2dw"
      },
      "source": [
        "###Предварительная обработка текстовых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4il3oZFY_Kw"
      },
      "source": [
        "Для того, чтобы применять текстовые данные для обучения той или иной модели машинного обучения, их нужно привести в подходящий для этого вид. В этом нам помогут следующие шаги предварительной подготовки:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfTWe_1oCrsd"
      },
      "source": [
        "####Приведение к нижнему регистру"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2GZxS6PZkcx"
      },
      "source": [
        "Так как слова (например) \"Beer\" и \"beer\" будут считаться разными словами из-за разницы в регистре буквы b, а первая буква предложения, как правило, является заглавной, важно привести все слова предложения к нижнему регистру. Таким образом, \"beer\", встретившееся в начале предложения и в его середине, будут распознаны как одно слово."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq9MqtqoW2ce"
      },
      "source": [
        "lowered = columns['lyrics'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYUruNhrCFjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8839ca13-736f-4fc0-fa0a-2e2e56cdf205"
      },
      "source": [
        "columns['lowered'] = lowered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4YULmIC9oZ"
      },
      "source": [
        "####Токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZZIXNXebXvi"
      },
      "source": [
        "Имеющиеся тексты нужно разбить на отдельные слова. Такой процесс называется ***токенизация***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ws0-pYLCpI5",
        "outputId": "ee38c21d-215f-4c79-e77a-b7d4e8592407"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxi9nYbMDGWa"
      },
      "source": [
        "tokened = columns.apply(lambda row: nltk.word_tokenize(row['lowered']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqSXoypQDNE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8d2ca1-3684-4f7e-b6c7-c3ab765321b2"
      },
      "source": [
        "columns['tokened'] = tokened"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOISss1fGOtf"
      },
      "source": [
        "####Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo0gIbfamIqr"
      },
      "source": [
        "***Стоп-словами*** называются распространённые слова, не несущие особой смысловой нагрузки, а значит никак не помогающие в последующей задаче классификации. Такие слова мы считаем шумом, и, соответственно, удаляем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKUN9izHnQfR"
      },
      "source": [
        "Существует специальный корпус стоп-слов на разных языках. Так как сейчас мы имеем дело с текстами на английском языке, выведем стоп-слова для английского:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkAzYAeDbhN",
        "outputId": "40954309-d9a9-40b6-e758-9baeb6d2a891"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43f5-hujGW7l"
      },
      "source": [
        "noise = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YFPt0YxGf9J"
      },
      "source": [
        "withoutstop = columns['tokened'].apply(lambda x: [item for item in x if item not in noise])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUp4qWzGlMr"
      },
      "source": [
        "without_stop = []\n",
        "for a in withoutstop:    \n",
        "    without_stop.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLJ1ezBGnoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed596317-2190-4cd6-8bb6-522e443e83a9"
      },
      "source": [
        "columns['without_stop'] = without_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWIlOfFOPId-"
      },
      "source": [
        "####Лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiNsgTkFPOjX"
      },
      "source": [
        "У одного и того же слова бывают разные формы. Например, dances - форма слова dance. Лемматизация - это приведение к ***лемме*** - исходной форме слова. Её также необходимо применить к нашим данным, чтобы разные формы слова не считались за отдельные слова."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KA2A_wgUUfW"
      },
      "source": [
        "Существует целый ряд лемматизаторов, которые показывают себя с разной эффективностью на разных языках. Для работы с английским языком эффективен **WordNetLemmatizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR5Lr4WzGt5Q",
        "outputId": "c0614585-e486-44b3-c417-e182d46ee74e"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i7WLP9-Z0_L",
        "outputId": "34ee488b-8548-4af4-e4dc-fa1a78e6f708"
      },
      "source": [
        "print(lemmatizer.lemmatize(\"dances\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcmk4VWvb7Mq"
      },
      "source": [
        "lemmatized = columns['without_stop'].apply(lambda x: [lemmatizer.lemmatize(x)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puuud0HJdJRy"
      },
      "source": [
        "lemma = []\n",
        "for a in lemmatized:    \n",
        "    lemma.append(\", \".join(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLDzaHFdMMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11bbcc3-43f9-440b-d990-66b2ba02cbf9"
      },
      "source": [
        "columns['lemmatized'] = lemma"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkfqMYftynRV"
      },
      "source": [
        "Таким образом, на каждом этапе мы добавляли столбец с той или иной модификацией, чтобы получить пригодные для обучения данные. Посмотрим на датафрейм, который получился:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "ixDtw5yEyklr",
        "outputId": "861ec1e9-2bde-4483-f148-838a3589806f"
      },
      "source": [
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>lowered</th>\n",
              "      <th>tokened</th>\n",
              "      <th>without_stop</th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>who am i, that the lord of all the earth woul...</td>\n",
              "      <td>[who, am, i, ,, that, the, lord, of, all, the,...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "      <td>,, lord, earth, would, care, know, name, would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>glory revealed  by his wounds he was pierced ...</td>\n",
              "      <td>[glory, revealed, by, his, wounds, he, was, pi...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "      <td>glory, revealed, wounds, pierced, transgressio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>lord of heaven and earth lord of all creation...</td>\n",
              "      <td>[lord, of, heaven, and, earth, lord, of, all, ...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "      <td>lord, heaven, earth, lord, creation, lord, hea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>i can only imagine what it will be like when ...</td>\n",
              "      <td>[i, can, only, imagine, what, it, will, be, li...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "      <td>imagine, like, walk, side, imagine, eyes, see,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>i am not skilled to understand what god has w...</td>\n",
              "      <td>[i, am, not, skilled, to, understand, what, go...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "      <td>skilled, understand, god, willed, ,, god, plan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Dirty dog Im, Im a dirty dog Im a dirty dog I...</td>\n",
              "      <td>dirty dog im, im a dirty dog im a dirty dog i...</td>\n",
              "      <td>[dirty, dog, im, ,, im, a, dirty, dog, im, a, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "      <td>dirty, dog, im, ,, im, dirty, dog, im, dirty, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Regulators, we regulate any stealing of his p...</td>\n",
              "      <td>regulators, we regulate any stealing of his p...</td>\n",
              "      <td>[regulators, ,, we, regulate, any, stealing, o...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "      <td>regulators, ,, regulate, stealing, property, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Have you ever met a girl that you tried to da...</td>\n",
              "      <td>have you ever met a girl that you tried to da...</td>\n",
              "      <td>[have, you, ever, met, a, girl, that, you, tri...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "      <td>ever, met, girl, tried, date, year, make, love...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Yo, yo, yo They wanna know  Whos that girl? (...</td>\n",
              "      <td>yo, yo, yo they wanna know  whos that girl? (...</td>\n",
              "      <td>[yo, ,, yo, ,, yo, they, wan, na, know, whos, ...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "      <td>yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>3 6 9, damn shes fine Hopin she can sock it t...</td>\n",
              "      <td>3 6 9, damn shes fine hopin she can sock it t...</td>\n",
              "      <td>[3, 6, 9, ,, damn, shes, fine, hopin, she, can...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "      <td>3, 6, 9, ,, damn, shes, fine, hopin, sock, one...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>185 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre  ...                                         lemmatized\n",
              "0    Christian  ...  ,, lord, earth, would, care, know, name, would...\n",
              "1    Christian  ...  glory, revealed, wounds, pierced, transgressio...\n",
              "2    Christian  ...  lord, heaven, earth, lord, creation, lord, hea...\n",
              "3    Christian  ...  imagine, like, walk, side, imagine, eyes, see,...\n",
              "4    Christian  ...  skilled, understand, god, willed, ,, god, plan...\n",
              "..         ...  ...                                                ...\n",
              "267    Hip-Hop  ...  dirty, dog, im, ,, im, dirty, dog, im, dirty, ...\n",
              "268    Hip-Hop  ...  regulators, ,, regulate, stealing, property, d...\n",
              "269    Hip-Hop  ...  ever, met, girl, tried, date, year, make, love...\n",
              "270    Hip-Hop  ...  yo, ,, yo, ,, yo, wan, na, know, whos, girl, ?...\n",
              "271    Hip-Hop  ...  3, 6, 9, ,, damn, shes, fine, hopin, sock, one...\n",
              "\n",
              "[185 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fTc3speuRU_"
      },
      "source": [
        "####Разделим данные на обучающую и тестовую выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slicW92xunS6"
      },
      "source": [
        "x_train - тексты, на которых мы обучаем модель. В данном случае мы используем столбец lemmatized, так как он содержит данные, прошедшие все этапы подготовки \n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_train - жанры, соответствующие текстам, на которых модель обучается - столбец genre\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "x_test - точно такие же тексты из набора данных, на которых мы будем проверять, насколько модель научилась предсказывать жанр\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "y_test - жанры, соответствующие x_test. т.е. мы смотрим, насколько предсказания соответствуют содержимому этой переменной, чтобы оценить качество обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNflRzghthgt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(columns.lemmatized, columns.genre, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUGVD0A2uWHs",
        "outputId": "5ce523ed-3a1c-4523-d5b3-8068568fb5c5"
      },
      "source": [
        "columns.genre.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Christian    94\n",
              "Hip-Hop      91\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvUGd5D45Lvg"
      },
      "source": [
        "####Векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOZdvHTa8y3U"
      },
      "source": [
        "Следующий этап - ***векторизация***, то есть представление текста в численном виде, чтобы закодированные данные в дальнейшем использовать на модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APRGsKZx5JVu"
      },
      "source": [
        "Иногда помимо отдельных слов для улучшения качества обучения будет полезно использовать также комбинации из 2-3 слов. Здесь мы используем векторизатор CountVectorizer, который имеет встроенный метод - мешок n-грамм.\n",
        "\n",
        "> n = 1 - униграмма (для обучения используются слова по отдельности)\n",
        "\n",
        "> n = 2 - биграмма (для обучения используются пары слов)\n",
        "\n",
        "> n = 3 - триграмма (для обучения используются тройки слов)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Qsuu8F24RX"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9eEKTEP-R_6"
      },
      "source": [
        "Задаём для векторизатора ngram_range=(1, 3), то есть используем все варианты n от 1 до 3 и прибегаем как к униграммам, так и к биграммам и триграммам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-7CcA8d24Dd"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9m6sTC0-lmB"
      },
      "source": [
        "### Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9TxA5ek-vvi"
      },
      "source": [
        "Для задачи классификации используем Наивный Байесовский Классификатор - простой вероятностный классификатор, основанный на применении теоремы Байеса со строгими предположениями о независимости. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Qo0JJPvzO7"
      },
      "source": [
        "#импортируем байесовский классификатор\n",
        "from sklearn.naive_bayes import MultinomialNB "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOJS1mskyLnf",
        "outputId": "c28330fe-8356-492f-afc9-563e4e9d9672"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUW3yo_FyLcr"
      },
      "source": [
        "# тестовую выборку просто векторизировали\n",
        "vectorized_x_test = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZ_Yn7j42JB"
      },
      "source": [
        "Посмотрим предсказания для тестовой выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwjjKPF64zTQ",
        "outputId": "28b0c74b-5833-4f45-cba6-df508f7ec990"
      },
      "source": [
        "clf.predict(vectorized_x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hip-Hop', 'Christian', 'Christian', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Christian', 'Hip-Hop', 'Christian',\n",
              "       'Hip-Hop', 'Christian', 'Christian', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian', 'Christian',\n",
              "       'Christian', 'Christian', 'Hip-Hop', 'Hip-Hop', 'Christian',\n",
              "       'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Christian', 'Hip-Hop',\n",
              "       'Christian', 'Hip-Hop', 'Christian', 'Hip-Hop', 'Christian',\n",
              "       'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Hip-Hop', 'Christian',\n",
              "       'Christian', 'Christian', 'Christian', 'Hip-Hop'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2sNKSRk46ao"
      },
      "source": [
        "Получим оценки классификации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W1R9x6J3GVS",
        "outputId": "bdfdc800-ee4b-4048-899a-1d512fb96abc"
      },
      "source": [
        "from sklearn.metrics import * \n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Christian       0.96      0.90      0.93        30\n",
            "     Hip-Hop       0.89      0.96      0.93        26\n",
            "\n",
            "    accuracy                           0.93        56\n",
            "   macro avg       0.93      0.93      0.93        56\n",
            "weighted avg       0.93      0.93      0.93        56\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxRZ_lI-4Da"
      },
      "source": [
        "###Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35zqDBC_ksBq"
      },
      "source": [
        "# 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Atec9Uy_CYJ"
      },
      "source": [
        "1) Запустить ячейку ниже, чтобы получить 2 жанра. Для полученных жанров провести все этапы предварительной обработки текста (как в примере), обучить наивный байесовский классификатор, численно оценить его работу."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxkZ901zyLPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8456efc2-4e5e-4e17-b545-99ce65ab3d2a"
      },
      "source": [
        " import random \n",
        " lst = ['Christian', 'Country', 'Pop', 'Rock', 'R&B'] \n",
        " print('ваши жанры', random.choice(lst), 'и', random.choice(lst)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ваши жанры Pop и Christian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbUnwn3ciOQh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "45fb400f-47df-4aeb-e90e-6e8f16437454"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.core.common import flatten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset.csv\")\n",
        "columns = data[['genre', 'lyrics']]\n",
        "columns = columns[(columns.genre == 'Christian') | (columns.genre == 'Pop')]\n",
        "\n",
        "columns['lowered'] = columns['lyrics'].str.lower()\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Who am I, that the Lord of all the earth Woul...</td>\n",
              "      <td>who am i, that the lord of all the earth woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Glory Revealed  By His Wounds He was pierced ...</td>\n",
              "      <td>glory revealed  by his wounds he was pierced ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christian</td>\n",
              "      <td>Lord of heaven and earth Lord of all creation...</td>\n",
              "      <td>lord of heaven and earth lord of all creation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I can only imagine what it will be like When ...</td>\n",
              "      <td>i can only imagine what it will be like when ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Christian</td>\n",
              "      <td>I am not skilled to understand What God has w...</td>\n",
              "      <td>i am not skilled to understand what god has w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Have you ever met a girl that you tried to da...</td>\n",
              "      <td>have you ever met a girl that you tried to da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Im outta luck, outta love Gotta photograph, p...</td>\n",
              "      <td>im outta luck, outta love gotta photograph, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>Pop</td>\n",
              "      <td>She was a fast machine  She kept her motor cl...</td>\n",
              "      <td>she was a fast machine  she kept her motor cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Good times, these are the good times Leave yo...</td>\n",
              "      <td>good times, these are the good times leave yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Pop</td>\n",
              "      <td>All the small things True care, truth brings ...</td>\n",
              "      <td>all the small things true care, truth brings ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         genre  ...                                            lowered\n",
              "0    Christian  ...   who am i, that the lord of all the earth woul...\n",
              "1    Christian  ...   glory revealed  by his wounds he was pierced ...\n",
              "2    Christian  ...   lord of heaven and earth lord of all creation...\n",
              "3    Christian  ...   i can only imagine what it will be like when ...\n",
              "4    Christian  ...   i am not skilled to understand what god has w...\n",
              "..         ...  ...                                                ...\n",
              "367        Pop  ...   have you ever met a girl that you tried to da...\n",
              "368        Pop  ...   im outta luck, outta love gotta photograph, p...\n",
              "369        Pop  ...   she was a fast machine  she kept her motor cl...\n",
              "370        Pop  ...   good times, these are the good times leave yo...\n",
              "371        Pop  ...   all the small things true care, truth brings ...\n",
              "\n",
              "[194 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnYH33ARj4e-"
      },
      "source": [
        "*Токенизация*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCFc_BYgTYot"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "i2CA_a8DjZq7",
        "outputId": "a97bec93-0b0e-4a2d-bf12-6e894894cb5d"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "tokened = columns.apply(lambda row: nltk.word_tokenize(row['lowered']), axis=1)\n",
        "columns['tokened'] = tokened"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3a7bd51232fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lowered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokened'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJI5ARGDkRZs"
      },
      "source": [
        "Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5nfwRPSjjdJ",
        "outputId": "5b49eae2-fed1-4b44-f39a-da5af23e2c0a"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdiGB8tjxcu"
      },
      "source": [
        "noise = stopwords.words('english')\n",
        "withoutstop = columns['tokened'].apply(lambda x: [item for item in x if item not in noise])\n",
        "without_stop = []\n",
        "for a in withoutstop:    \n",
        "    without_stop.append(\", \".join(a))\n",
        "columns['without_stop'] = without_stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiWXAS7vkUmW"
      },
      "source": [
        "Лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gta_y3VHj1KR",
        "outputId": "54feef53-67ab-4804-e72e-d2018eccbede"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVahFd0Qj3S8"
      },
      "source": [
        "lemmatized = columns['without_stop'].apply(lambda x: [lemmatizer.lemmatize(x)])\n",
        "lemma = []\n",
        "for a in lemmatized:    \n",
        "    lemma.append(\", \".join(a))\n",
        "columns['lemmatized'] = lemma    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zdmXqQsk9FY"
      },
      "source": [
        "Разделение данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTHHCjZUkhmO",
        "outputId": "87208659-812b-4059-e1d6-57d9edaaa8bf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(columns.lemmatized, columns.genre, train_size = 0.7)\n",
        "columns.genre.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pop          100\n",
              "Christian     94\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2p2wpOClLVx"
      },
      "source": [
        "Векторизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3T9yG_FlKWb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QEGphj8lRkW"
      },
      "source": [
        "Классификация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFIDzJSAlQ3K"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "vectorized_x_test = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk4wEc_6loL4"
      },
      "source": [
        "Оценка классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOsoS6aTlu7z",
        "outputId": "d7b0599e-0a76-4b03-a92a-d9eaf120cd15"
      },
      "source": [
        "from sklearn.metrics import * \n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Christian       0.93      0.90      0.92        30\n",
            "         Pop       0.90      0.93      0.92        29\n",
            "\n",
            "    accuracy                           0.92        59\n",
            "   macro avg       0.92      0.92      0.92        59\n",
            "weighted avg       0.92      0.92      0.92        59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI1rVEg_kwCf"
      },
      "source": [
        "# 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWdnLBHf_onv"
      },
      "source": [
        "2) Найти (нагуглить) по песне каждого из жанров, которые Вам достались, после необходимой обработки их текстов определить жанр обеих песен с помощью обученной в ходе выполнения предыдущего пункта модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHHk6-MfpFkS",
        "outputId": "40958fe1-016d-4dbe-a003-0b344178fb61"
      },
      "source": [
        "music = ['I can only imagine What it will be like When I walk by Your side I can only imagine What my eyes would see When Your face is before me I can only imagine Yeah Surrounded by Your glory What will my heart feel? Will I dance for You Jesus Or in awe of You be still? Will I stand in Your presence Or to my knees, will I fall? Will I sing hallelujah? Will I be able to speak at all? I can only imagine I can only imagine I can only imagine When that day comes And I find myself Standing in the Son I can only imagine When all I will do Is forever, forever worship You I can only imagine, yeah I can only imagine Surrounded by Your glory What will my heart feel? Will I dance for you Jesus Or in awe of You be still? Will I stand in your presence Or to my knees will I fall? Will I sing hallelujah? Will I be able to speak at all? I can only imagine, yeah I can only imagine Surrounded by Your glory What will my heart feel? Will I dance for you Jesus Or in awe of You be still? Will I stand in your presence Or to my knees, will I fall? Will I sing hallelujah? Will I be able to speak at all? I can only imagine, yeah I can only imagine I can only imagine, yeah-yeah I can only imagine I can only imagine I can only imagine I can only imagine When all I will do Is forever, forever worship You I can only imagine', \n",
        "            'Oh I cannot explain Every time it is the same Oh I feel that it is real Take my heart I have been lonely too long Oh I can not be so strong Take a chance for romance Take my heart I need you so There is no time I will ever go Cheri Cheri Lady Going through emotion Love is where you find it Listen to your heart Cheri Cheri Lady Living in devotion Always like the first time Let me take a part Cheri Cheri Lady Like there is no tomorrow Take my heart don not lose it Listen to your heart Cheri Cheri Lady To know you is to love you If you call me baby I will be always yours I get up and get down Oh my world turns around Who is right, who is wrong I don not know I have got pain in my heart Gotta love in my soul Easy come but I think easy go I need you so All those times I am not so strong Cheri Cheri Lady Going through emotion Love is where you find it Listen to your heart Cheri Cheri Lady Living in devotion Always like the first time Let me take a part Cheri Cheri Lady Like there is no tomorrow Take my heart don not lose it Listen to your heart Cheri Cheri Lady To know you is to love you If you call me baby I will be always yours'] \n",
        "#нижний регистр\n",
        "music_lower = list(map(str.lower, music))\n",
        "#токенизация\n",
        "music_tok = [nltk.word_tokenize(i) for i in music_lower]\n",
        "music_tokened = list(flatten(music_tok))\n",
        "#удаление стоп-слов\n",
        "music_withoutstop = list(set(music_tokened) - set(noise))\n",
        "#лемматизация\n",
        "music_pro = [lemmatizer.lemmatize(i) for i in music_withoutstop]\n",
        "\n",
        "#векторизация\n",
        "vectorized_mus = vectorizer.transform(music) \n",
        "clf.predict(vectorized_mus)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Christian', 'Pop'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o3_83FKK9R4"
      },
      "source": [
        "# 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtmpuwX6AZy6"
      },
      "source": [
        "3) С помощью набора данных по ссылке аналогичным образом научить модель отличать тексты песен Дэвида Боуи от текстов песен Пола МакКартни \n",
        "https://www.kaggle.com/italomarcelo/dataset-lyrics-music-mini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShnlTrZkK9R5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce7b91c-c1f0-424f-84cd-ce4c5ed242e7"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.core.common import flatten\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "dat = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/dataset-lyrics-musics-mini.csv\")\n",
        "columns = dat[['cantorNome', 'letra']]\n",
        "columns = columns[(columns.cantorNome == 'david-bowie') | (columns.cantorNome == 'paul-mccartney')]\n",
        "\n",
        "columns['lowered'] = columns['letra'].str.lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o377PHZK9R6"
      },
      "source": [
        "*Токенизация*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHUS4l81K9R6",
        "outputId": "b33bfbf5-2681-41dc-cc97-76b21abb3cb0"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "tokened = columns.apply(lambda row: nltk.word_tokenize(row['lowered']), axis=1)\n",
        "columns['tokened'] = tokened"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN1MUlQuK9R6"
      },
      "source": [
        "Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN5e_QAzK9R6",
        "outputId": "6b90eb5e-f32b-4656-d528-436216558057"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brNL9UUEK9R6"
      },
      "source": [
        "noise = stopwords.words('english')\n",
        "withoutstop = columns['tokened'].apply(lambda x: [item for item in x if item not in noise])\n",
        "without_stop = []\n",
        "for a in withoutstop:    \n",
        "    without_stop.append(\", \".join(a))\n",
        "columns['without_stop'] = without_stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq3QzxRuK9R6"
      },
      "source": [
        "Лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIzTKuvEK9R6",
        "outputId": "c6103f19-431b-4e34-c60f-bec3a81c3915"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSzyIolyK9R7"
      },
      "source": [
        "lemmatized = columns['without_stop'].apply(lambda x: [lemmatizer.lemmatize(x)])\n",
        "lemma = []\n",
        "for a in lemmatized:    \n",
        "    lemma.append(\", \".join(a))\n",
        "columns['lemmatized'] = lemma    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE4PDjq6K9R7"
      },
      "source": [
        "Разделение данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYJA4POGTymQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuExKPBVK9R7",
        "outputId": "27e3985f-b90b-4319-88d2-13aaf9902973"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "x_train, x_test, y_train, y_test = train_test_split(columns.lemmatized, columns.cantorNome, train_size = 0.7)\n",
        "columns.cantorNome.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "david-bowie       483\n",
              "paul-mccartney    464\n",
              "Name: cantorNome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bdzQxwtK9R7"
      },
      "source": [
        "Векторизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdi40suwK9R7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "vectorized_x_train = vectorizer.fit_transform(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znQekWmJK9R7"
      },
      "source": [
        "Классификация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl60JpH2K9R7"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "vectorized_x_test = vectorizer.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbU2PCsfK9R7"
      },
      "source": [
        "Оценка классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm8ibQEWK9R8",
        "outputId": "8b63d1ff-526b-4991-cf84-7c65d2f781f5"
      },
      "source": [
        "from sklearn.metrics import * \n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "   david-bowie       0.73      0.74      0.73       141\n",
            "paul-mccartney       0.74      0.74      0.74       144\n",
            "\n",
            "      accuracy                           0.74       285\n",
            "     macro avg       0.74      0.74      0.74       285\n",
            "  weighted avg       0.74      0.74      0.74       285\n",
            "\n"
          ]
        }
      ]
    }
  ]
}